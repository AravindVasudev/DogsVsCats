{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0 of 12494\n",
      "Processed 250 of 12494\n",
      "Processed 500 of 12494\n",
      "Processed 750 of 12494\n",
      "Processed 1000 of 12494\n",
      "Processed 1250 of 12494\n",
      "Processed 1500 of 12494\n",
      "Processed 1750 of 12494\n",
      "Processed 2000 of 12494\n",
      "Processed 2250 of 12494\n",
      "Processed 2500 of 12494\n",
      "Processed 2750 of 12494\n",
      "Processed 3000 of 12494\n",
      "Processed 3250 of 12494\n",
      "Processed 3500 of 12494\n",
      "Processed 3750 of 12494\n",
      "Processed 4000 of 12494\n",
      "Processed 4250 of 12494\n",
      "Processed 4500 of 12494\n",
      "Processed 4750 of 12494\n",
      "Processed 5000 of 12494\n",
      "Processed 5250 of 12494\n",
      "Processed 5500 of 12494\n",
      "Processed 5750 of 12494\n",
      "Processed 6000 of 12494\n",
      "Processed 6250 of 12494\n",
      "Processed 6500 of 12494\n",
      "Processed 6750 of 12494\n",
      "Processed 7000 of 12494\n",
      "Processed 7250 of 12494\n",
      "Processed 7500 of 12494\n",
      "Processed 7750 of 12494\n",
      "Processed 8000 of 12494\n",
      "Processed 8250 of 12494\n",
      "Processed 8500 of 12494\n",
      "Processed 8750 of 12494\n",
      "Processed 9000 of 12494\n",
      "Processed 9250 of 12494\n",
      "Processed 9500 of 12494\n",
      "Processed 9750 of 12494\n",
      "Processed 10000 of 12494\n",
      "Processed 10250 of 12494\n",
      "Processed 10500 of 12494\n",
      "Processed 10750 of 12494\n",
      "Processed 11000 of 12494\n",
      "Processed 11250 of 12494\n",
      "Processed 11500 of 12494\n",
      "Processed 11750 of 12494\n",
      "Processed 12000 of 12494\n",
      "Processed 12250 of 12494\n",
      "Processed 0 of 12500\n",
      "Processed 250 of 12500\n",
      "Processed 500 of 12500\n",
      "Processed 750 of 12500\n",
      "Processed 1000 of 12500\n",
      "Processed 1250 of 12500\n",
      "Processed 1500 of 12500\n",
      "Processed 1750 of 12500\n",
      "Processed 2000 of 12500\n",
      "Processed 2250 of 12500\n",
      "Processed 2500 of 12500\n",
      "Processed 2750 of 12500\n",
      "Processed 3000 of 12500\n",
      "Processed 3250 of 12500\n",
      "Processed 3500 of 12500\n",
      "Processed 3750 of 12500\n",
      "Processed 4000 of 12500\n",
      "Processed 4250 of 12500\n",
      "Processed 4500 of 12500\n",
      "Processed 4750 of 12500\n",
      "Processed 5000 of 12500\n",
      "Processed 5250 of 12500\n",
      "Processed 5500 of 12500\n",
      "Processed 5750 of 12500\n",
      "Processed 6000 of 12500\n",
      "Processed 6250 of 12500\n",
      "Processed 6500 of 12500\n",
      "Processed 6750 of 12500\n",
      "Processed 7000 of 12500\n",
      "Processed 7250 of 12500\n",
      "Processed 7500 of 12500\n",
      "Processed 7750 of 12500\n",
      "Processed 8000 of 12500\n",
      "Processed 8250 of 12500\n",
      "Processed 8500 of 12500\n",
      "Processed 8750 of 12500\n",
      "Processed 9000 of 12500\n",
      "Processed 9250 of 12500\n",
      "Processed 9500 of 12500\n",
      "Processed 9750 of 12500\n",
      "Processed 10000 of 12500\n",
      "Processed 10250 of 12500\n",
      "Processed 10500 of 12500\n",
      "Processed 10750 of 12500\n",
      "Processed 11000 of 12500\n",
      "Processed 11250 of 12500\n",
      "Processed 11500 of 12500\n",
      "Processed 11750 of 12500\n",
      "Processed 12000 of 12500\n",
      "Processed 12250 of 12500\n",
      "(24943, 64, 64, 3) (24943,)\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset\n",
    "dogsDir = './dataset/Dog/'\n",
    "catsDir = './dataset/Cat/'\n",
    "\n",
    "SIZE = (64, 64)\n",
    "\n",
    "dogs = [dogsDir+i for i in os.listdir(dogsDir)]\n",
    "cats = [catsDir+i for i in os.listdir(catsDir)]\n",
    "\n",
    "def read_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_COLOR) # read as grayscale\n",
    "    return cv2.resize(img, SIZE, interpolation=cv2.INTER_CUBIC) # resize to 64x64\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "def add_to_dataset(arr, label):\n",
    "    count = len(arr)\n",
    "    for i, file in enumerate(arr):\n",
    "        try:\n",
    "            X.append(read_image(file))\n",
    "            y.append(label)\n",
    "            \n",
    "            if i%250 == 0: print('Processed {} of {}'.format(i, count))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "add_to_dataset(cats, 0)\n",
    "add_to_dataset(dogs, 1)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split data into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train image generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "# test image generator\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train batch\n",
    "batches = train_datagen.flow(X_train, y_train,  batch_size=64)\n",
    "\n",
    "# validation batch\n",
    "validation_batches = test_datagen.flow(X_test, y_test,  batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 128)         204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 783,425\n",
      "Trainable params: 783,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ** model start **\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 5, activation='relu', input_shape=(64, 64, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Convolution2D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# **model end **\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='rmsprop',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "234/234 [==============================] - 73s 310ms/step - loss: 0.6815 - acc: 0.5737 - val_loss: 0.6134 - val_acc: 0.6666\n",
      "Epoch 2/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.6146 - acc: 0.6660 - val_loss: 0.5601 - val_acc: 0.7073\n",
      "Epoch 3/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.5598 - acc: 0.7186 - val_loss: 0.5069 - val_acc: 0.7424\n",
      "Epoch 4/80\n",
      "234/234 [==============================] - 67s 286ms/step - loss: 0.5209 - acc: 0.7445 - val_loss: 0.4655 - val_acc: 0.7754\n",
      "Epoch 5/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.4882 - acc: 0.7661 - val_loss: 0.4877 - val_acc: 0.7667\n",
      "Epoch 6/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.4633 - acc: 0.7831 - val_loss: 0.4214 - val_acc: 0.8061\n",
      "Epoch 7/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.4476 - acc: 0.7899 - val_loss: 0.4262 - val_acc: 0.8040\n",
      "Epoch 8/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.4201 - acc: 0.8056 - val_loss: 0.4561 - val_acc: 0.7847\n",
      "Epoch 9/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.4165 - acc: 0.8126 - val_loss: 0.3781 - val_acc: 0.8247\n",
      "Epoch 10/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3991 - acc: 0.8189 - val_loss: 0.3729 - val_acc: 0.8302\n",
      "Epoch 11/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3864 - acc: 0.8269 - val_loss: 0.3866 - val_acc: 0.8288\n",
      "Epoch 12/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3828 - acc: 0.8306 - val_loss: 0.3990 - val_acc: 0.8235\n",
      "Epoch 13/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3724 - acc: 0.8349 - val_loss: 0.4884 - val_acc: 0.7940\n",
      "Epoch 14/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3683 - acc: 0.8361 - val_loss: 0.3905 - val_acc: 0.8210\n",
      "Epoch 15/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3565 - acc: 0.8451 - val_loss: 0.3386 - val_acc: 0.8480\n",
      "Epoch 16/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3440 - acc: 0.8495 - val_loss: 0.4125 - val_acc: 0.8367\n",
      "Epoch 17/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3441 - acc: 0.8502 - val_loss: 0.3578 - val_acc: 0.8398\n",
      "Epoch 18/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3398 - acc: 0.8553 - val_loss: 0.3338 - val_acc: 0.8496\n",
      "Epoch 19/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3281 - acc: 0.8576 - val_loss: 0.3407 - val_acc: 0.8598\n",
      "Epoch 20/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3269 - acc: 0.8610 - val_loss: 0.3843 - val_acc: 0.8402\n",
      "Epoch 21/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3248 - acc: 0.8607 - val_loss: 0.3272 - val_acc: 0.8598\n",
      "Epoch 22/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3243 - acc: 0.8601 - val_loss: 0.3252 - val_acc: 0.8529\n",
      "Epoch 23/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3175 - acc: 0.8673 - val_loss: 0.3123 - val_acc: 0.8615\n",
      "Epoch 24/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3141 - acc: 0.8659 - val_loss: 0.4621 - val_acc: 0.8403\n",
      "Epoch 25/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3247 - acc: 0.8652 - val_loss: 0.4137 - val_acc: 0.8442\n",
      "Epoch 26/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3183 - acc: 0.8693 - val_loss: 0.3241 - val_acc: 0.8607\n",
      "Epoch 27/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3153 - acc: 0.8679 - val_loss: 0.3124 - val_acc: 0.8679\n",
      "Epoch 28/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3133 - acc: 0.8712 - val_loss: 0.3309 - val_acc: 0.8688\n",
      "Epoch 29/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3124 - acc: 0.8687 - val_loss: 0.3404 - val_acc: 0.8495\n",
      "Epoch 30/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3052 - acc: 0.8713 - val_loss: 0.3274 - val_acc: 0.8654\n",
      "Epoch 31/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3103 - acc: 0.8709 - val_loss: 0.4726 - val_acc: 0.7734\n",
      "Epoch 32/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3104 - acc: 0.8706 - val_loss: 0.3748 - val_acc: 0.8605\n",
      "Epoch 33/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3150 - acc: 0.8677 - val_loss: 0.3048 - val_acc: 0.8621\n",
      "Epoch 34/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3013 - acc: 0.8747 - val_loss: 0.3427 - val_acc: 0.8476\n",
      "Epoch 35/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3070 - acc: 0.8712 - val_loss: 0.3227 - val_acc: 0.8629\n",
      "Epoch 36/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3096 - acc: 0.8726 - val_loss: 0.3446 - val_acc: 0.8433\n",
      "Epoch 37/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3172 - acc: 0.8690 - val_loss: 0.3494 - val_acc: 0.8522\n",
      "Epoch 38/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3043 - acc: 0.8731 - val_loss: 0.3165 - val_acc: 0.8572\n",
      "Epoch 39/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3221 - acc: 0.8687 - val_loss: 0.3941 - val_acc: 0.8181\n",
      "Epoch 40/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3104 - acc: 0.8722 - val_loss: 0.6386 - val_acc: 0.8226\n",
      "Epoch 41/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.2996 - acc: 0.8752 - val_loss: 0.3027 - val_acc: 0.8655\n",
      "Epoch 42/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3146 - acc: 0.8703 - val_loss: 0.3197 - val_acc: 0.8608\n",
      "Epoch 43/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3121 - acc: 0.8710 - val_loss: 0.3208 - val_acc: 0.8703\n",
      "Epoch 44/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3172 - acc: 0.8693 - val_loss: 0.3227 - val_acc: 0.8798\n",
      "Epoch 45/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3139 - acc: 0.8709 - val_loss: 0.3753 - val_acc: 0.8328\n",
      "Epoch 46/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3136 - acc: 0.8684 - val_loss: 0.2907 - val_acc: 0.8792\n",
      "Epoch 47/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3263 - acc: 0.8640 - val_loss: 0.4200 - val_acc: 0.8574\n",
      "Epoch 48/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3154 - acc: 0.8653 - val_loss: 0.3941 - val_acc: 0.8724\n",
      "Epoch 49/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3275 - acc: 0.8650 - val_loss: 0.4732 - val_acc: 0.8287\n",
      "Epoch 50/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3409 - acc: 0.8643 - val_loss: 0.3516 - val_acc: 0.8742\n",
      "Epoch 51/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3376 - acc: 0.8625 - val_loss: 0.3089 - val_acc: 0.8685\n",
      "Epoch 52/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3216 - acc: 0.8647 - val_loss: 0.5018 - val_acc: 0.7516\n",
      "Epoch 53/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3232 - acc: 0.8660 - val_loss: 0.8767 - val_acc: 0.7747\n",
      "Epoch 54/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3234 - acc: 0.8677 - val_loss: 0.3673 - val_acc: 0.8307\n",
      "Epoch 55/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3251 - acc: 0.8682 - val_loss: 0.3227 - val_acc: 0.8668\n",
      "Epoch 56/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3261 - acc: 0.8667 - val_loss: 0.3799 - val_acc: 0.8278\n",
      "Epoch 57/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3214 - acc: 0.8676 - val_loss: 0.3238 - val_acc: 0.8743\n",
      "Epoch 58/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3374 - acc: 0.8644 - val_loss: 0.3027 - val_acc: 0.8727\n",
      "Epoch 59/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3302 - acc: 0.8646 - val_loss: 0.3034 - val_acc: 0.8802\n",
      "Epoch 60/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3475 - acc: 0.8643 - val_loss: 0.4548 - val_acc: 0.7576\n",
      "Epoch 61/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3351 - acc: 0.8645 - val_loss: 0.3256 - val_acc: 0.8733\n",
      "Epoch 62/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3370 - acc: 0.8633 - val_loss: 0.3186 - val_acc: 0.8614\n",
      "Epoch 63/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3485 - acc: 0.8555 - val_loss: 0.5063 - val_acc: 0.7809\n",
      "Epoch 64/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3486 - acc: 0.8557 - val_loss: 0.4012 - val_acc: 0.8208\n",
      "Epoch 65/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3564 - acc: 0.8596 - val_loss: 0.4084 - val_acc: 0.8496\n",
      "Epoch 66/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3446 - acc: 0.8562 - val_loss: 0.3211 - val_acc: 0.8660\n",
      "Epoch 67/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3576 - acc: 0.8537 - val_loss: 0.4191 - val_acc: 0.8094\n",
      "Epoch 68/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3535 - acc: 0.8543 - val_loss: 0.4139 - val_acc: 0.8692\n",
      "Epoch 69/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3603 - acc: 0.8579 - val_loss: 0.3789 - val_acc: 0.8599\n",
      "Epoch 70/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3853 - acc: 0.8507 - val_loss: 0.3117 - val_acc: 0.8608\n",
      "Epoch 71/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3609 - acc: 0.8586 - val_loss: 0.4047 - val_acc: 0.8630\n",
      "Epoch 72/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3820 - acc: 0.8494 - val_loss: 0.3661 - val_acc: 0.8708\n",
      "Epoch 73/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3753 - acc: 0.8458 - val_loss: 0.3036 - val_acc: 0.8702\n",
      "Epoch 74/80\n",
      "234/234 [==============================] - 67s 287ms/step - loss: 0.3809 - acc: 0.8460 - val_loss: 0.4846 - val_acc: 0.8082\n",
      "Epoch 75/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3901 - acc: 0.8470 - val_loss: 0.5547 - val_acc: 0.8041\n",
      "Epoch 76/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3883 - acc: 0.8470 - val_loss: 0.3118 - val_acc: 0.8605\n",
      "Epoch 77/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3770 - acc: 0.8507 - val_loss: 0.3558 - val_acc: 0.8477\n",
      "Epoch 78/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3808 - acc: 0.8466 - val_loss: 0.3384 - val_acc: 0.8537\n",
      "Epoch 79/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3676 - acc: 0.8511 - val_loss: 0.8438 - val_acc: 0.8694\n",
      "Epoch 80/80\n",
      "234/234 [==============================] - 67s 288ms/step - loss: 0.3973 - acc: 0.8484 - val_loss: 0.3405 - val_acc: 0.8546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0a2a3b3b00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit_generator(\n",
    "    batches,\n",
    "    epochs=80,\n",
    "    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "model.save('dogsvscats.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
